# -*- coding: utf-8 -*-
"""projectAkhir_capstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ddmDeRlpz_nABvetKgsJa1fEyZFqV004
"""

!pip install split-folders tqdm

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import splitfolders
import os
from sklearn.model_selection import train_test_split
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator
import zipfile,os

"""Input Folder untuk dibagi menjadi train dan val"""

base_dir = '/content/drive/MyDrive/Colab Notebooks/skripsi/uang'

"""# Preprocessing"""

splitfolders.ratio(
    base_dir,
    output='ready_dataset',
    ratio=(.7, 0.1,0.2)
)

"""Menambahkan masing masing folder untuk train dan validation"""

train_dir = 'ready_dataset/train'
val_dir = 'ready_dataset/val' 
test_dir = 'ready_dataset/test'

os.listdir(test_dir)

from keras.preprocessing.image import ImageDataGenerator

#def to_grayscale_then_rgb(image):
    #original = tf.constant([[[32, 150, 3.0]]])
    #image = tf.image.rgb_to_grayscale(image)
    #return image

# augmentasi gambar
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20, # memutar gambar
                    brightness_range=(0.5,1.0), # value < 1 lebih gelap
                    shear_range=0.2, # untuk mengatur skala image
                    zoom_range=(0.8,1.0), # value < 1 akan zoom in
                    fill_mode='nearest', # untuk mengisi gambar atau wadah yang tidak memiliki nilai
                    #preprocessing_function=to_grayscale_then_rgb,
                    horizontal_flip=True,
                    vertical_flip=True)

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir, # direktori data train
    target_size=(150,150), # mengubah resolusi seluruh gambar jadi 150*150
    batch_size=32,# untuk menentukan jumlah image yang akan dimasukkan ke dalam steps training
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(150,150),
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150,150),
    batch_size=32,
    class_mode='categorical'
)

"""# Visualisasi"""

class_name = ['Uang lima puluh ribu', 'Uang sepuluh ribu', 'Uang seratus ribu']

image, label = train_generator.next()

"""### Jumlah Keseluruhan Data

#### Pallet warna Visualisasi
"""

palette1 = list(reversed(sns.color_palette("mako", 7).as_hex()))
palette2 = list(reversed(sns.color_palette("viridis", 7).as_hex()))
palette3 = list(reversed(sns.color_palette("cubehelix", 7).as_hex()))
palette4 = list(reversed(sns.color_palette("icefire", 7).as_hex()))

"""#### Jumlah Data Semuanya"""

len(image)

label

print(image.shape)

# gambar = tf.reshape(image[3],(150,150))

#plt.imshow(gambar)

plt.figure(figsize=(7,7))
for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(image[i])
  plt.title(class_name[np.argmax(label[i])])
  plt.axis("off")

for _ in range(7):
  img, label = train_generator.next() # method mengembalikkan data
  print(img.shape)   #  (1,256,256,3)
  plt.imshow(img[i])
  plt.show()

"""# Modeling"""

from tensorflow import keras

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)), #input layer
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax') # output Layer
])

model.summary()

from tensorflow.keras.utils import plot_model
plot_model(model,'model.png',show_shapes=True)

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""# Training"""

history = model.fit(
    train_generator,
    epochs=15,
    validation_data=val_generator, # untuk akurasi pengujian data
)

"""### Visualisasi Akurasi"""

plt.figure(1, figsize=(10,10))
plt.plot(range(len(history.history['accuracy'])), 
         history.history['accuracy'],
         'co-',
         label='training')
plt.plot(range(len(history.history['val_accuracy'])), 
         history.history['val_accuracy'],
         'bD--',
         label='validation')
plt.legend()
plt.show()

plt.figure(1, figsize=(10,10))
plt.plot(range(len(history.history['loss'])), 
         history.history['loss'],
         'mo-',
         label='training')
plt.plot(range(len(history.history['val_loss'])), 
         history.history['val_loss'],
         'rD--',
         label='validation')
plt.legend()
plt.show()

"""### Save Model diatas"""

model.save('/capstone/Save Model')
model.save('capstone/Save Model.h5')

"""# Evaluate"""

test_evaluate = model.evaluate(test_generator, verbose=0)

print(f'Test loss     : {test_evaluate[0]}')
print(f'Test accuracy : {round(test_evaluate[1],2)}') #dibulatkan 2 artinya 2 angka di belakang koma

"""# Preview Hasil Prediksi"""

image ,label = next(iter(test_generator))

plt.figure(figsize=(15,10))
for i in range(9) :
    TrueLabel = class_name[np.argmax(label[i])]
    plt.subplot(3,3,i+1)
    plt.axis('off')
    y_pred = np.argmax(model.predict(image[i][None,...],verbose=0))
    plt.imshow(tf.squeeze(image[i]))
    plt.title(f'label: {TrueLabel}, predict : {class_name[y_pred]}')

"""# Prediksi Error

# Classification report dan Confusin Matrix
"""

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

y_pred = model.predict(test_generator)

y_pred

y_predict = np.argmax(y_pred, axis=1)

print(classification_report(test_generator.labels, y_predict, target_names = class_name))

"""# Confusion Matrix"""

plt.figure(figsize=(20, 16))
cm = confusion_matrix(test_generator.labels, y_predict)

sns.heatmap(cm,annot=True,fmt='d',xticklabels=class_name,yticklabels=class_name)
plt.title("Confusion Matrix - Test Set")
plt.show()

"""# Mencoba Program dengan upload data gambar untuk di cek hasilnya"""

#  upload = files.upload() buat pas make google colab

# # from google.colab import files
# from tkinter import Tk
# from tkinter.filedialog import askopenfilename
# from tensorflow.keras.utils import load_img
# from keras.preprocessing import image
# from tensorflow.keras.preprocessing.image import img_to_array
# import matplotlib.image as mpimg
# import numpy as np
# %matplotlib inline
# import tensorflow as tf
# import matplotlib.pyplot as plt
# import numpy as np
# import seaborn as sns
# import splitfolders
# import os
# from sklearn.model_selection import train_test_split
# import tensorflow as tf
# import matplotlib.pyplot as plt
# from tensorflow.keras.preprocessing import image
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
# import keras_preprocessing
# from keras_preprocessing import image
# from keras_preprocessing.image import ImageDataGenerator
# import zipfile,os

# Commented out IPython magic to ensure Python compatibility.
# from google.colab import files
from tkinter import Tk
from tkinter.filedialog import askopenfilename
from tensorflow.keras.utils import load_img
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import img_to_array
import matplotlib.image as mpimg
import numpy as np
# %matplotlib inline
from google.colab import drive
from sklearn.model_selection import train_test_split
import tensorflow as tf
import matplotlib.pyplot as plt

import os

from google.colab import files
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator
import zipfile,os

!pip install gtts

!pip install playsound

# import dependencies
from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode, b64encode
import cv2
import numpy as np
import PIL
import io
import html
import time
from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode, b64encode
import cv2
import numpy as np
import PIL
import io
import html
import time
from playsound import playsound
from gtts import gTTS
import os
from IPython.display import Audio

# function to convert the JavaScript object into an OpenCV image
def js_to_image(js_reply):
  """
  Params:
          js_reply: JavaScript object containing image from webcam
  Returns:
          img: OpenCV BGR image
  """
  # decode base64 image
  image_bytes = b64decode(js_reply.split(',')[1])
  # convert bytes to numpy array
  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)
  # decode numpy array into OpenCV BGR image
  img = cv2.imdecode(jpg_as_np, flags=1)

  return img

# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream
def bbox_to_bytes(bbox_array):
  """
  Params:
          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.
  Returns:
        bytes: Base64 image byte string
  """
  # convert array into PIL image
  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')
  iobuf = io.BytesIO()
  # format bbox into png for return
  bbox_PIL.save(iobuf, format='png')
  # format return string
  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))

  return bbox_bytes

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)

  # get photo data
  data = eval_js('takePhoto({})'.format(quality))
  # get OpenCV format image
  img = js_to_image(data) 
  # grayscale img
  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
  print(gray.shape)
  # save image
  cv2.imwrite(filename, img)

  return filename

try:
  filename = take_photo('photo.jpg')
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))

print("|===========================================|")
print("|              PREDIKSI GAMBAR              |")
print("|===========================================|")

img = image.load_img(filename, target_size=(150, 150))                              
imgplot = plt.imshow(img)                                                     
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

Gambar = np.vstack([x])
File = model.predict(Gambar, batch_size=10)
print(filename)

if File[0][0]==1:
  def limapuluh():
    output = gTTS('uang lima puluh', lang='id',slow = False) 
    output.save('lima puluh.mp3')
   # playsound("seribu.mp3")
    print("lima puluh")
  limapuluh()
elif File[0][1]==1:
  def sepuluhu():
    output = gTTS('uang sepuluh ribu', lang='id',slow = False) 
    output.save('sepuluh.mp3') 
   # playsound("seribu.mp3") 
    print("sepuluh")
  sepuluhu()         
elif File[0][2]==1:
  def seratus():
    output = gTTS('uang seratus', lang='id',slow = False) 
    output.save('seratus.mp3')
   # playsound("seribu.mp3")  
    print("seratus")
  seratus()                                 
else:
  def eror():
    output = gTTS('Gambar Tidak di ketahui', lang='id',slow = False) 
    output.save('eror.mp3')
    playsound("eror.mp3")
    print('Gambar Tidak di ketahui')  
  eror()       
print("|===========================================|")